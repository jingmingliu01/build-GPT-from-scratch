{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPOYePm7rPykdvHcvB0wJLY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingmingliu01/build-GPT-from-scratch/blob/main/bigram_build_GPT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import"
      ],
      "metadata": {
        "id": "LwamkOGGLNmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkU91uzTbFoP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.hyperparameters"
      ],
      "metadata": {
        "id": "zGBckDgeLX5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "block_size=8\n",
        "max_iters=3000\n",
        "eval_interval=300\n",
        "learning_rate=1e-2\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters=200\n",
        "\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXqleo_DLb7S",
        "outputId": "6d734c4d-93af-41e0-ca8c-c1c3aff4b938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b0f1052f210>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88Zut9ySMCvI",
        "outputId": "1dffad1a-3cb3-4f03-9794-edcce78999f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 04:27:52--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.2’\n",
            "\n",
            "\rinput.txt.2           0%[                    ]       0  --.-KB/s               \rinput.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-24 04:27:52 (18.4 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt','r',encoding='utf-8') as f:\n",
        "  text=f.read()"
      ],
      "metadata": {
        "id": "XKhyuKuaMSjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.data preparation"
      ],
      "metadata": {
        "id": "_UKEZblKLuWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)\n",
        "stoi={ch:i for i,ch in enumerate(chars)}\n",
        "itos={i:ch for i,ch in enumerate(chars)}\n",
        "encode=lambda s:[stoi[c] for c in s]\n",
        "decode=lambda l:''.join([itos[i] for i in l])\n",
        "\n",
        "data=torch.tensor(encode(text),dtype=torch.long)\n",
        "n=int(0.9*len(data))\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]"
      ],
      "metadata": {
        "id": "fqFVG11yMORQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.data loading"
      ],
      "metadata": {
        "id": "fQvVTh3KNCvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "  data=train_data if split=='train' else val_data\n",
        "  ix=torch.randint(len(data)-block_size,(batch_size,))\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  x,y=x.to(device),y.to(device)\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "KWucxuQ3NBtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train','val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X,Y=get_batch(split)\n",
        "      logits,loss=model(X,Y)\n",
        "      losses[k]=loss.item()\n",
        "    out[split]=losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "-aYD0fE3N5-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.model define"
      ],
      "metadata": {
        "id": "CXZM-v8CVwWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    logits=self.token_embedding_table(idx)\n",
        "\n",
        "    if targets is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T,C)\n",
        "      targets=targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits,targets)\n",
        "\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits,loss = self(idx)\n",
        "      logits=logits[:,-1,:]\n",
        "      probs = F.softmax(logits,dim=-1)\n",
        "      idx_next=torch.multinomial(probs,num_samples=1)\n",
        "      idx=torch.cat((idx,idx_next),dim=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "IlmyT7IvOyCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.train and generate"
      ],
      "metadata": {
        "id": "1qhRfXamYWAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=BigramLanguageModel(vocab_size)\n",
        "m=model.to(device)\n",
        "\n",
        "optimizer=torch.optim.AdamW(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "-5etENl0X49r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "  if iter % eval_interval==0:\n",
        "    losses=estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb,yb=get_batch('train')\n",
        "\n",
        "  logits,loss=model(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--bUY9ZhYnmu",
        "outputId": "acd8a879-b427-4292-b561-059c20c89067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.7305, val loss 4.7241\n",
            "step 300: train loss 2.8110, val loss 2.8249\n",
            "step 600: train loss 2.5434, val loss 2.5682\n",
            "step 900: train loss 2.4932, val loss 2.5088\n",
            "step 1200: train loss 2.4863, val loss 2.5035\n",
            "step 1500: train loss 2.4665, val loss 2.4921\n",
            "step 1800: train loss 2.4683, val loss 2.4936\n",
            "step 2100: train loss 2.4696, val loss 2.4846\n",
            "step 2400: train loss 2.4638, val loss 2.4879\n",
            "step 2700: train loss 2.4738, val loss 2.4911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context=torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "print(decode(m.generate(context,max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZJWklMMZDLz",
        "outputId": "b842b8fe-ae68-4538-e21e-640a23c3ce23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "CEThik brid owindakis b, bth\n",
            "\n",
            "HAPet bobe d e.\n",
            "S:\n",
            "O:3 my d?\n",
            "LUCous:\n",
            "Wanthar u qur, t.\n",
            "War dXENDoate awice my.\n",
            "\n",
            "Hastarom oroup\n",
            "Yowhthetof isth ble mil ndill, ath iree sengmin lat Heriliovets, and Win nghir.\n",
            "Swanousel lind me l.\n",
            "HAshe ce hiry:\n",
            "Supr aisspllw y.\n",
            "Hentofu n Boopetelaves\n",
            "MPOLI s, d mothakleo Windo whth eisbyo the m dourive we higend t so mower; te\n",
            "\n",
            "AN ad nterupt f s ar igr t m:\n",
            "\n",
            "Thin maleronth,\n",
            "Mad\n",
            "RD:\n",
            "\n",
            "WISo myrangoube!\n",
            "KENob&y, wardsal thes ghesthinin couk ay aney IOUSts I&fr y ce.\n",
            "J\n"
          ]
        }
      ]
    }
  ]
}